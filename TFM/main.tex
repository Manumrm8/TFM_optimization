\documentclass[12pt,a4paper]{book}

% Formato del documento
%\usepackage[papersize={210mm,297mm},inner=3.5cm,outer=2cm,top=2.5cm,bottom=2.5cm]{geometry}
%\renewcommand{\baselinestretch}{1}
%\setlength{\parskip}{8pt}

\usepackage[utf8]{inputenc}
\usepackage{amssymb}
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{tikz}
\usepackage{tkz-graph}
\usepackage{hyperref}
\usepackage[parfill]{parskip}
\usepackage{float}
\renewcommand{\chaptername}{Capítulo}
\renewcommand{\contentsname}{Índice}
\renewcommand{\bibname}{Bibliografía}
\renewcommand{\figurename}{Figura}

\definecolor{verde_oscuro}{rgb}{0.0, 0.5, 0.0}

\newtheorem{defi}{Definición}[section]
\newtheorem{prop}{Proposición}[section]
\newtheorem{propi}{Propiedades}[section]
\newtheorem{lema}{Lema}[section]
\newtheorem{tma}{Teorema}[section]
\newtheorem{cor}{Corolario}[section]
\newtheorem{nota}{Nota}[section]
\newtheorem{ejem}{Ejemplo}[section]

\hypersetup{
    colorlinks=true,
    linkcolor=blue,
    filecolor=magenta,      
    urlcolor=cyan,
    pdftitle={Overleaf Example},
    pdfpagemode=FullScreen,
    }

\urlstyle{same}

%%%%%%%ALTERNATIVA 2%%%%%%%%%%%%
\textheight=21cm
\textwidth=17cm
%\topmargin=-1cm
\oddsidemargin=0cm
\evensidemargin=0cm
\parindent=0mm
\pagestyle{plain}
%%%%%%%%%%%%%%%%%%%%%

%%%%%%%  Comando Portada  %%%%%%%%%%%
% Ajustes de geometría si la portada sigue sin caber
% \geometry{a4paper, top=1cm, bottom=1cm, left=1cm, right=1cm} 

\newcommand{\nuevaportada}[6]{
    \thispagestyle{empty}
    \begin{center}
        \includegraphics[width=0.5\textwidth]{images/logo.png}
        
        \vspace{0.3cm} % Espacio reducido
        {\Large\bfseries\textsc{M\'aster Universitario en #1}\par}
        
        \vspace{0.3cm} % Espacio reducido
        \includegraphics[width=0.4\textwidth]{images/uv.png}
        
        \vspace{0.3cm} % Espacio reducido
        {\Large\bfseries\textsc{Trabajo de Fin de M\'aster}\par}
        
        \vspace{0.5cm} % Mantener este espacio un poco más grande para el título
        {\Large\bfseries #2\par}
        
        \vspace{1.5cm} % Reducido a 1.5cm desde 2cm
        \begin{flushright}
            \begin{tabular}{l} 
                {\large\bfseries\textsc{Autor:}} \\
                {\large\textsc{#3}} \\ [0.3cm] % Espacio reducido
                {\large\bfseries\textsc{Tutora:}} \\ 
                {\large\textsc{#4}} \\ [0.3cm] % Espacio reducido
                {\large\bfseries #5} 
            \end{tabular}
        \end{flushright}
    \end{center}
    % Eliminamos \clearpage de aquí, ya que la portada debe ser una sola página
    % Si necesitas un salto de página después de la portada, lo añades en el documento principal.
}

\begin{document}

\nuevaportada{Ciencia de Datos}{Problema de Localización de Centros k-Balanceado Multiobjetivo}{Manuel Rubio Martínez}{Anna Martínez Gavara}{Abril, 2025}

\clearpage

\newpage
\tableofcontents

\newpage

\section*{Resumen}
Aquí va el contenido de tu resumen en español. Explica brevemente el objetivo, la metodología, los resultados y las conclusiones de tu TFM.

\newpage

\section*{Abstract}
Here goes the content of your abstract in English. Briefly explain the objective, methodology, results, and conclusions of your TFM.

\newpage

\section*{Resum}
Aquí va el contingut del teu resum en valencià. Explica breument l'objectiu, la metodologia, els resultats i les conclusions del teu TFM.

\newpage

\chapter{Preliminares}
\section{Introducción}
\begin{defi}[Dominio de una función]
Dada una función $f: X \to Y$, su \textbf{dominio} es el conjunto de todos los valores de entrada para los cuales la función está definida. En este caso, el dominio es $X$.
\end{defi}

\begin{defi}[Imagen de una función]
Dada una función $f: X \to Y$, su \textbf{imagen} es el subconjunto formado por todos los valores que la función toma realmente. Se denota como $\text{Im}(f)$ o $f(X)$, y se define como:
$$ f(X) = \{y \in Y \mid \exists x \in X, f(x) = y \} $$
\end{defi}

\begin{defi}[Conjunto convexo]
Un conjunto $C \subseteq \mathbb{R}^n$ es \textbf{convexo} si para cualquier par de puntos $x, y \in C$, el segmento de recta que los une está completamente contenido en $C$. Formalmente, para todo $x, y \in C$ y para todo $\lambda \in [0, 1]$:
$$ \lambda x + (1-\lambda)y \in C $$
\end{defi}

\begin{defi}[Función lineal]
Una función $f: \mathbb{R}^n \to \mathbb{R}^m$ es \textbf{lineal} si satisface dos propiedades: aditividad y homogeneidad. Es decir, para cualesquiera vectores $\mathbf{x}, \mathbf{y} \in \mathbb{R}^n$ y cualquier escalar $\alpha \in \mathbb{R}$:
\begin{enumerate}
    \item $f(\mathbf{x}+\mathbf{y}) = f(\mathbf{x}) + f(\mathbf{y})$ (Aditividad)
    \item $f(\alpha \mathbf{x}) = \alpha f(\mathbf{x})$ (Homogeneidad de grado 1)
\end{enumerate}
\end{defi}

\begin{defi}[Función continua]
Intuitivamente, una función $f$ es continua si cambios pequeños en la entrada provocan cambios pequeños en la salida (no hay saltos abruptos). Formalmente, una función $f: X \to Y$ es continua en un punto $c \in X$ si para todo $\epsilon > 0$, existe un $\delta > 0$ tal que si la distancia de $x$ a $c$ es menor que $\delta$, entonces la distancia de $f(x)$ a $f(c)$ es menor que $\epsilon$.
$$ \forall \epsilon > 0, \exists \delta > 0 : |x-c| < \delta \implies |f(x)-f(c)| < \epsilon $$
La función es continua en su dominio si es continua en todos sus puntos.
\end{defi}

\begin{defi}[Función diferenciable]
Una función real de una variable real $f: \mathbb{R} \to \mathbb{R}$ es \textbf{diferenciable} en un punto $x_0$ de su dominio si su derivada existe en ese punto. Esto significa que la función puede ser aproximada localmente por una función lineal (su recta tangente) en el entorno de $x_0$. Formalmente, si el siguiente límite existe:
$$ f'(x_0) = \lim_{h \to 0} \frac{f(x_0+h) - f(x_0)}{h} $$
Para funciones de varias variables, $f: \mathbb{R}^n \to \mathbb{R}^m$, la diferenciabilidad implica la existencia de una transformación lineal  que aproxima el comportamiento de la función en un punto.
\end{defi}

\begin{defi}[Conjunto numerable]
Un conjunto es \textbf{numerable} (o contable) si existe una correspondencia uno a uno entre los elementos del conjunto y un subconjunto de los números naturales $\mathbb{N} = \{1, 2, 3, \dots\}$. Esto significa que se puede crear una lista (finita o infinita) que contenga todos los elementos del conjunto. El conjunto de los números enteros $\mathbb{Z}$ y el de los números racionales $\mathbb{Q}$ son numerables, mientras que el conjunto de los números reales $\mathbb{R}$ no lo es.
\end{defi}
\section{Modelo Matemático}

\begin{defi}
Un algoritmo \textbf{"greedy"} (codicioso) es un método construcción de soluciones para un problema de optimización,
de manera que en cada paso se escoge la mejor posible, aunque esto no lleve finalmente a un óptimo global.
\end{defi}

\bigskip

\begin{defi}
Un algoritmo \textbf{"greedy randomizado"} se basa en el "greedy", pero en cada paso se elige de forma aleatoria entre un conjunto de mejores opciones.
Si el conjunto de opciones es el total, el algoritmo es "random".
\end{defi}

\chapter{Introducción}
La optimización es una de las ramas fundamentales dentro de las matemáticas aplicadas.  Se utiliza tanto en economía como en ingeniería informática o ciencias naturales y sociales.

En esencia, la optimización trata de encontrar la mejor solución posible a un problema.

Un problema de optimización se compone de tres elementos clave:
\begin{itemize}
    \item Variables de decisión: Las carreteras que tomar en una ruta, el número de personas a contratar para un trabajo, o las ubicaciones en las que construir una instalación.
    \item Función objetivo: El criterio que se desea tomar, tanto minimizar (costes, tiempos de producción, distancias) o maximizar (eficacia de anuncios publicitarios, beneficios, o la supervivencia en tratamientos médicos).
    \item Restricciones del problema: límite de carga de camiones, un presupuesto máximo a gastar, limitaciones de maquinaria o de personal etc.
\end{itemize}


Para abordar estos problema de manera sistemática y eficiente, la optimización a menudo implica formular de forma matemática, simplificando las variables del caso real a un plano abstracto donde sea más práctico resolverlos. 

\section{Historia de la optimización}
El origen de la optimización se remonta a la antigua Grecia, donde matemáticos como Euclides y Arquímedes la utilizaban para buscar soluciones a problemas en el área de la geometría.

La versión que conocemos hoy en día no empezó a desarrollarse hasta el siglo XVII, con el desarrollo del cálculo diferencial por parte de Isaac Newton y Gottfried Wihelm Leibniz, con la que se empezaron a estudiar las funciones y sus puntos extremos,
donde se encontraban sus máximos y minimos.

No hubo grandes avances hasta mitad del siglo XX, cuando fruto de la necesidad de resolver problemas logísticos durante la Segunda Guerra Mundial, se desarrolló la programación lineal (creada por el matemático George Dantzig),
que sentó las bases para el posterior surgimiento de la programación no lineal, programación entera y programación dinámica.

A pesar de todos estos avances la mayoría de problemas del mundo real, especialmente aquellos que dependen de un gran número de variables, con funciones objetivo complejas y restricciones no lineales,
acaban siendo demasiado complejos computacionalmente para tratar de buscar su solución exacta, lo que propició el surgimiento de los metaheurísticos.

Los algoritmos metaheurísticos (que explicaremos en profundidad más adelante) plantan la semilla de la optimización moderna. La búsqueda de soluciones aproximadas pero próximas al óptimo, en un tiempo de procesamiento aceptable.

Para la ciencia de datos serán cruciales para el desarrollo de algoritmos en diversos ámbitos:
\begin{itemize}
    \item \textbf{Clustering:} El algoritmo \textbf{k-means} particiona el espacio de observaciones en un número determinado de clústeres (grupos) y determina qué observaciones pertenecen a cada uno de ellos. 
    Si intentasemos encontrar la solución exacta, sería computacionalmente muy costoso, y la naturaliza del algoritmo hace que la solución sea dependiente de los grupos iniciales (generados aleatoriamente), cayendo en óptimos locales.
    Las metaheurísticas ayudan a solventar estos problemas.
    \item \textbf{Selección de variables:} En la construcción de modelos de predicción, solemos encontrarnos con gran cantidad de variables, para las cuales definir el modelo en base a todas ellas no es factible. Mediante metaheurísticos podemos 
    reducir significativamente la dimensión del espacio, utilizando un subespacio con las variables que sirvan mejor al modelo.
    \item \textbf{Ajuste de hiperparámetros:} Modelos de inteligencia artificial como redes neuronales necesitan ajustar sus hiperparámetros para ser eficaces. Esto también es un problema de optimización, donde los Metaheurísticos pueden superar la típica \textit{búsqueda en cuadrícula} de parámetros.
\end{itemize}

\color{red} citar a Libros de texto sobre optimización y algoritmos heurísticos: Por ejemplo, "Metaheuristics: From Design to Implementation" de E.K. Burke y G. Kendall, o "Introduction to Optimization" de E.J. Anderson. \color{black}

\section{Formulación Matemática}

Para expresar un problema de optimización de forma matemática, definimos las tres partes en las que se puede descomponer:

\begin{itemize}
    \item \textbf{Variables de Decisión:} Las incógnitas del problema. Son los valores que deberemos modificar para obtener la solución o soluciones óptimas. Se representan como un vector $\mathbf{x} = (x_1, x_2, \ldots, x_n)$, donde $n$ es el número de variables.

    \item \textbf{Función Objetivo:} Función que se desea minimizar o maximizar. Se denota comúnmente como $f(\mathbf{x})$, donde $f$ es la función que establece la relación entre variables ($\mathbf{x}$) y el objetivo que deseamos optimizar.
    Por ejemplo:
    $$ \min_{\mathbf{x}} f(\mathbf{x}) \quad \text{o} \quad \max_{\mathbf{x}} f(\mathbf{x}) $$
    La función $f: \mathbb{R}^n \to \mathbb{R}$ mapea el vector de variables a un valor escalar, el cual buscaremos mejorar.

    \item \textbf{Restricciones:} Son las condiciones o limitaciones que deben satisfacer las variables de decisión. Pueden ser de igualdad o de desigualdad. Se expresan generalmente como:
    \begin{align*}
        g_i(\mathbf{x}) &\le 0 & \quad \text{para } i = 1, \ldots, m \\
        h_j(\mathbf{x}) &= 0 & \quad \text{para } j = 1, \ldots, p
    \end{align*}
    Donde $g_i(\mathbf{x})$ son las $m$ restricciones de desigualdad y $h_j(\mathbf{x})$ son las $p$ restricciones de igualdad.
    En caso de tener restricciones del tipo $g_k(\mathbf{x})\geq0$, se puede pasar a $\leq$ sabiendo que $-g_k(\mathbf{x})=g'_k(\mathbf{x})\leq0$.
    
    Además de restricciones funcionales, también pueden existir restricciones sobre el dominio de las variables, como $x_k \ge 0$ (variables no negativas) o $x_k \in \{0,1\}$ (variables binarias).
\end{itemize}

Ahora si, pasadas las definiciones previas, un problema completo de optimización se formula de la siguiente manera:
$$
\begin{array}{ll}
\text{Minimizar (o Maximizar)} & f(\mathbf{x}) \\ \\
\text{Sujeto a:} & g_i(\mathbf{x}) \le 0, \quad i = 1, \ldots, m \\
& h_j(\mathbf{x}) = 0, \quad j = 1, \ldots, p \\
& \mathbf{x} \in X
\end{array}
$$
Donde $X$ representa el conjunto de factibilidad o dominio de las variables de decisión.

\subsection{Tipos de Óptimos: Global vs. Local}

En optimización, es fundamental distinguir entre los distintos tipos de soluciones óptimas, ya que la función objetivo puede tener múltiples puntos donde alcance valores extremos. Por eso hay que diferenciar entre los óptimos locales y globales.

\subsubsection{Óptimo Global}
Un óptimo global es el mejor valor posible que, dentro del dominio de factibilidad de $\mathbf{X}$, puede tomar la función objetivo. Esto significa que no existe ninguna otra solución que ofrezca un valor estrictamente mejor que el del óptimo global.

Es la solución que siempre querremos obtener al resolver un problema de optimización.

Si estamos minimizando $f(\mathbf{x}$), el punto $\mathbf{x}^* \in \mathbf{X}$ es un óptimo global si
$$f(\mathbf{x}^*)\leq f(\mathbf{x}) \quad \forall \mathbf{x}\in X$$

\subsubsection{Óptimo Local}

Un ótimo local es un punto donde la función objetivo alcanza el mejor valor posible dentro de una región próxima, pero no necesariamente todo el dominio. Pueden existir infinidad de óptimos locales.

Si estamos minimizando $f(\mathbf{x})$, el punto $\mathbf{x}^* \in \mathbf{X}$ es un óptimo local si existe un $\epsilon>0$ tal que
$$f(\mathbf{x}^*)\leq f(\mathbf{x}) \quad \forall \mathbf{x}\in X \text{ que cumpla que }||\mathbf{x}-\mathbf{x}^*||<\epsilon$$
Donde $||\cdot||$ denota una métrica de distancia.

Un par de ejemplos para distinguir los dos tipos de óptimos:
\begin{itemize}
    \item Si consideramos la elevación de la superficie terrestre como la función objetivo a maximizar, un \textbf{óptimo local} será la cima de cualquier montaña. Es el punto más alto si consideramos como entorno próximo la prompia montaña.
    \item En contraste, el \textbf{óptimo global} sería la cima del Monte Everest, el punto más alto de toda la geografía terrestre.
\end{itemize}

\subsection{Optimización Lineal vs. No Lineal}

En la clasificación de los problemas de optimización hay que tener muy en cuenta la forma matemática de sus funciones, tanto de la objetivo como de las restricciones. Esta parte es clave porque determina si el problema puede ser resuelto fácilmente de manera exacta, o se requerirá de métodos más complejos con soluciones aproximadas.

\subsubsection{Optimización Lineal}
Un problema diremos que es de optimización lineal cuando, tanto la función objetivo como todas las funciones de las restricciones son lineales (con respecto a las variables de decisión). 

Características principales:
\begin{itemize}
    \item La función objetivo tiene la forma $f(\mathbf{x})=c_1x_1+c_2x_2+...+c_nx_n$ con los $c_i \in \mathbb{R} \quad \forall i \in 1,2,...,n$.
    \item Todas las restricciones son lineales, con la forma $a_1x_1+a_2x_2+...+a_nx_n\leq b$ o $=b$.
    \item Todas estas condiciones hacen que el conjunto de soluciones factibles ($X$) tenga la forma de un poliedro convexo, lo que simplifica la búsqueda del óptimo.
    \item El algoritmo más extendido para resolver este tipo de problemas es el método Simplex, que garantiza encontrar el óptimo global, en caso de que exista. Para más información del algoritmo, está explicado en detalle en la publicación del creador del mismo en \cite{Dantzig1951}
\end{itemize}

Algunos ejemplos:
\begin{itemize}
    \item Planificación de la producción: Una fábrica busca maximizar su beneficio produciendo varios artículos, donde cada uno consume una cantidad fija de recursos (horas de máquina, materia prima) y genera un beneficio fijo. Las limitaciones vienen dadas por la disponibilidad de los recursos.
    \item Problema de la dieta: Minimizar el coste de una dieta que cumpla con requerimientos nutricionales mínimos, sabiendo que cada alimento aporta una cantidad fija de nutrientes por unidad.
\end{itemize}




\subsubsection{Optimización No Lineal}
El problema entra en esta categoría cuando, al menos una de sus funciones (objetivo o de restricción) es no lineal con respecto a sus variables de decisión. 

Características principales:
\begin{itemize}
    \item La función objetivo $f(\mathbf{x})$ o alguna de sus restricciones $g_i(\mathbf{x})$ o $h_j(\mathbf{x})$ contiene términos no lineales. Por ejemplo:
    $$f(\mathbf{x})=2x_1^2+5x_2^7-ln(x)$$
    \item Esto hace que el conjunto de soluciones factibles pueda ser no convexo, por lo que puede tener múltiples óptimos locales y no suele ser sencillo encontrar el óptimo global.
    \item La mayoría de algoritmos para resolverlos suelen utilizar técnicas de búsqueda local, y no garantizan encontrar el óptimo global.
\end{itemize}

Por ejemplo, casi cualquier problema que requiera minimizar distancias necesitará utilizar funciones cuadráticas (raíces y cuadrados) para poder calcular dichas distancias.
También para el ajuste de modelos, como encontrar los parámetros de una curva que se ajustan con unos datos concretos, minimizando el error cuadrático entre la aproximación (la curva) y el valor exacto de los datos, es una función no lineal.



\subsection{Optimización Discreta vs. Continua}
Es fundamental distinguir entre los 2 tipos de problemas que existen en optimización dependiendo de la naturaleza de las variables de decisión que se tomen en cuenta. Esto influye en el tipo de algoritmos y herramientas matemáticas que se podrán utilizar para resolverlos.

\subsubsection{Optimización Continua}
En la optimización continua, las variables de decisión pueden tomar cualquier valor real dentro de su dominio o rango permitido. Es decir, no están restringidas a tomar valores enteros, a un conjunto finito, o a un conjunto numerable de posibles soluciones. Esto las hace adecuadas para modelar fenómenos que varían de forma suave, como el tiempo, espacio, temperatura etc.

Características principales:
\begin{itemize}
    \item Variables pertenecientes a un espacio continuo, típicamente $\mathbb{R}^n$
    \item Las funciones objetivo $f(\mathbf{x})$ y sus restricciones $g_i(\mathbf{x}), \;h_j(\mathbf{x})$ suelen ser continuas y diferenciables.
    \item Las técnicas de resolución a menudo involucran cálculo diferencial para encontrar el mejor camino por el que mejorar la solución.
\end{itemize}
Algunos ejemplos incluyen el diseño aerodinámico de un avión, donde se optimizan los parámetros de las curvas que modelizan la forma de la superficie, la gestión de carteras de inversión, determinando qué porcentaje se asigna a cada activo para maximizar los retornos, o la optimización de la velocidad de un vehículo para reducir al máximo el consumo de combustible.

\subsubsection{Optimización Discreta}
En este caso las variables de decisión están restringidas a tomar valores de un conjunto finito o, al menos, numerable. Los casos más comunes incluyen variables enteras (0,1,2...), variables binarias (0,1), o variables que representan la elección de elementos de un conjunto específico (por ejemplo, el "trabajador 1" o el "trabajador 2").

Características principales:
\begin{itemize}
    \item Las variables pertenecen al espacio discreto.
    \item No se pueden utilizar directamente las técnicas de cálculo diferencial que, en cambio, si se podrían usar en el espacio continuo.
    \item Los problemas suelen ser más complejos de resolver y computacionalmente más costosos, por lo que suelen requerir algoritmos específicos como la programación entera, programación dinámica o métodos combinatorios para poder resolverlos.
\end{itemize}
Los ejemplos más tipicos son la planificación de rutas; asignación de recursos para resolver ciertas tareas (qué empleados se asignan a qué tareas); la ubicación de centros de distribución; o el problema de la mochila (escoger el mayor valor en elementos de un conjunto sin exceder una capacidad dada).

Para estas primeras partes introductorias he tomado como referencia el libro \cite{Numerical_optimization_nocedal_wright} de Numerical Optimization de Jorge Nocedal y Stephen J. Wright

\section{Optimización Combinatoria}
La optimización combinatoria es una rama de la optimización y las matemáticas aplicadas que se centra en encontrar una solución óptima dentro de un conjunto de soluciones finito o numerable. Aunque la cantidad de posibles soluciones pueda ser finita, esto no implica que el problema sea sencillo. De hecho, la gran mayoría de los problemas de optimización combinatoria pertenecen a la clase de complejidad NP-difícil.

La naturaleza NP-difícil de estos problemas implica que el tiempo necesario para encontrar la solución óptima crece de manera exponencial a medida que aumenta el tamaño del problema. Esto hace que la búsqueda exhaustiva de la solución sea computacionalmente inviable para la mayoría de los casos de estudio del mundo real.

\textbf{Características principales:}
\begin{itemize}
    \item \textbf{Espacio de soluciones discreto:} Las variables de decisión están restringidas a un conjunto finito o numerable de valores, como la selección o no de un elemento, o la ordenación de un conjunto.
    \item \textbf{Complejidad computacional elevada:} A menudo, el número de soluciones posibles es astronómicamente grande, lo que requiere algoritmos especializados para explorar el espacio de búsqueda de manera eficiente.
    \item \textbf{Estructura del problema:} Las técnicas de resolución aprovechan la estructura combinatoria subyacente del problema, utilizando métodos como la programación entera, la teoría de grafos o los algoritmos metaheurísticos.
\end{itemize}

Un ejemplo fundamental, que además es la base del problema tratado en este TFM, es la \textbf{selección de un subconjunto}. El objetivo es encontrar, en un conjunto de $n$ elementos, un subconjunto de tamaño $k$ que optimice (minimice o maximice) una o varias funciones objetivo. El número total de subconjuntos posibles viene dado por el coeficiente binomial:

$$
    \binom{n}{k} = \frac{n!}{(n-k)!k!}
$$

Para ilustrar la explosión combinatoria, consideremos un caso simple con $n=50$ y $k=5$. El número de combinaciones posibles es:

$$
    \binom{50}{5} = \frac{50!}{(50-5)!5!} = 2,118,760
$$

Si escalamos el problema a dimensiones más realistas, como $n=5000$ y $k=50$, la cantidad de soluciones posibles se dispara a una cifra del orden de $2.28 \times 10^{120}$. Evaluar cada una de estas soluciones para encontrar la óptima de forma exacta es una tarea imposible, incluso para los superordenadores más potentes, ya que requeriría tiempos de computación astronómicos.

Otros ejemplos clásicos de optimización combinatoria incluyen el \textbf{Problema del Viajante de Comercio (TSP)}, que busca la ruta más corta que visita un conjunto de ciudades una sola vez; el \textbf{problema de la mochila}, que consiste en seleccionar los objetos más valiosos sin superar una capacidad de peso; o la \textbf{planificación de horarios}, donde se asignan recursos (como aulas o profesores) a franjas horarias para satisfacer un conjunto de restricciones.

\section{Optimización Multiobjetivo}

\color{red} Aquí falta meterle las ventajas con respecto a la monoobjetivo \color{black}

A diferencia de la optimización tipica mono-objetivo, donde se busca optimizar una única función, la optimización multiobjetivo aborda problemas en los que es necesario mejorar simultáneamente dos o más funciones objetivo que, a menudo, están en conflicto entre sí. Mejorar una suele llevar al empeoramiento de ka otra. Por ejemplo, en el diseño de un vehículo, minimizar el consumo de combustible (objetivo 1) puede estar en conflicto con maximizar la potencia del motor (objetivo 2).

Aquí radica la diferencia fundamental con la optimización mono-objetivo. No existe el concepto de ``solución óptima''. Raramente existe una única solución que sea la mejor para todos los objetivos a la vez. En su lugar, lo que se busca es encontrar un conjunto de soluciones que representen las mejores soluciones posibles.

Este conjunto de soluciones se conoce como \textbf{Frente de Pareto}. Una solución es \textbf{no dominada} (óptima en el sentido de Pareto) si no existe otra solución que la mejore en todas las evaluaciones de su función objetivo.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.6\textwidth]{images/pareto_front.png}
    \caption{Ilustración de un Frente de Pareto para un problema de minimización con dos objetivos ($f_1, f_2$). Las soluciones en verde son óptimas, y pertenecen al frente de pareto, ya que no se puede mejorar un objetivo sin empeorar el otro. El punto ideal, que estaría en la parte inferior izquierda de la gráfica, sería la mejor solución imaginable combinando lo mejor de todas las soluciones. Luego las soluciones sin colorear están dominadas por alguna de las verdes\cite{Bre2017}.}
    \label{fig:pareto}
\end{figure}

\subsection{Métodos Exactos}

Los métodos exactos para la optimización multiobjetivo tienen como finalidad encontrar el Frente de Pareto completo y con total precisión. Sin embargo, al igual que en sus contrapartes mono-objetivo, estos métodos se enfrentan a un obstáculo formidable: la complejidad computacional. La mayoría de los problemas de optimización combinatoria multiobjetivo son \textbf{NP-hard}.

Algunos de los más conocidos son:

\begin{itemize}
    \item \textbf{Métodos de Ponderación (Weighted Sum):} transforman el problema multiobjetivo en problemas mono-objetivo, asignando un peso a cada función objetivo y sumándolas para crear una única función agregada. Al variar sistemáticamente los pesos, se pueden generar diferentes puntos del Frente de Pareto. Sin embargo, este método no garantiza encontrar todas las soluciones del frente si este tiene una forma no convexa.

    \item \textbf{Método de las Restricciones-$\epsilon$ ($\epsilon$-constraint):} Consiste en optimizar una de las funciones objetivo mientras las demás se convierten en restricciones, limitando su valor a un máximo $\epsilon$. Modificando los valores de $\epsilon$ para cada objetivo-restricción, se puede explorar y reconstruir el Frente de Pareto. A diferencia del método de ponderación, este sí puede encontrar soluciones en frentes no convexos.

    \item \textbf{Algoritmos de Ramificación y Acotación (Branch and Bound) Multiobjetivo:} Estos algoritmos extienden el clásico \textit{Branch and Bound}. El proceso de ramificación es similar (se divide el problema en subproblemas más pequeños), pero la fase de acotación (o poda) es más compleja. En lugar de usar una única cota, se trabaja con conjuntos de cotas (un vector por cada objetivo). Una rama del árbol de búsqueda se poda solo si se puede demostrar que no puede contener ninguna solución no dominada en comparación con las soluciones ya encontradas.

    \item \textbf{Algoritmos de Ramificación y Corte (Branch and Cut) Multiobjetivo:} De manera análoga, esta técnica extiende \textit{Branch and Cut}. Se añaden planos de corte (restricciones adicionales) no solo para mejorar la relajación del problema mono-objetivo, sino para refinar la aproximación del espacio de soluciones factibles en el dominio multiobjetivo, permitiendo podar ramas del árbol de búsqueda de forma más eficiente.
\end{itemize}

El principal inconveniente de todos estos métodos exactos es su coste computacional. La necesidad de encontrar un conjunto de soluciones (el Frente de Pareto) en lugar de una sola, y la complejidad de las operaciones de poda y comparación, hacen el método exacto muy lento. Por esta razón, en la práctica, para problemas de gran tamaño, se suelen preferir los métodos heurísticos o metaheurísticos, que buscan una buena aproximación del Frente de Pareto en un tiempo razonable.



\subsection{Metaheurísticos}
Las metaheurísticas aparecen con el desarrollo de las ciencias de la computación, como principal solución a estos problemas. Donde los métodos exactos no serían capaces de encontrar el óptimo,
los Metaheurísticos buscan soluciones `buenas` en tiempos de ejecución razonables, sacrificando la garantía que proporcionan los métodos exactos de obtener un óptimo global.

Generalmente combinan heurísticas para obtener soluciones buenas, con aleatoriedad, para conseguir una exploración
más ámplia del conjunto de soluciones posibles, buscando un balance entre exploración y explotación del entorno de soluciones.\\
Exploración ya que no se quedan bloqueados en regiones aisladas, intentando buscar óptimos locales, sino que recorren el resto del espacio buscando nuevas soluciones.\\
Explotación porque cuando entran en una región, profundizan en ella buscando los mejores óptimos locales.

Son algoritmos muy generales, fáciles de implementar y adaptables a casi 
cualquier problema de optimización.

Los principales metaheurísticas son:
\begin{itemize}
    \item Algoritmos Genéticos (GA - Genetic Algorithms)\\
    Inspirados en la selección natural y el funcionamiento de la genética, se basan en la generación aleatoria de soluciones, y el cruce de las más prometedoras entre sí, 
    añadiendo mutaciones. El cruce de las más prometedoras crea soluciones buenas, mientras las mutaciones aumentan la diversidad.
    \item Recocido Simulado (SA - Simulated Annealing)\\
    Basada en la física, se basa en el proceso de recocer metales (calentarlos y enfriarlos para alterar su estructura). Explora soluciones aceptando movimientos de mejora, pero también que puedan empeorar, 
    en función de una probabilidad dependiente de la "temperatura", que decrece con el paso de las iteraciones. Al principio, una temperatura alta favorece la exploración, y al final una baja favorece la explotación.
    \item Búsqueda Tabú (TS - Tabu Search)
    Genera una lista `Tabú` que actúa como memoria del algoritmo, incluyendo los movimientos recientes con el objetivo de no repetir soluciones recientes, sino explorar nuevas, aunque estas no sean las mejores posibles. Esto favorece la exploración.
    \item Optimización por Colonia de Hormigas (ACO - Ant Colony Optimization)
    Diseñado para problemas de rutas, construyendo soluciones iterativamente a través de un grafo, cuyas aristas  se van pesando a medida que generan soluciones buenas.
    \item GRASP (Greedy Randomized Adaptive Search Procedure)
    Algoritmo fundamentado en dos partes. Una primera, de construcción, en la que se genera una solución aleatorizada, y una segunda en la que se intenta mejorar la solución generada cambiando elementos de la misma.
\end{itemize}

\section{Motivación Ciencia de Datos}

\section{Aprendizaje Reforzado}

\section{Resumen del capítuo}

\chapter{Modelo matematico}

\section{Problemas de localización}

Los \textbf{problemas de localización} son uno de los tipos principales de optimización combinatoria, que buscan determinar la ubicación óptima para construir instalaciones, como almacenes, centros de distribución, hospitales, escuelas o estaciones de bomberos. 

Algunos de los objetivos a optimizar pueden incluir la minimización de la distancia total o máxima a los clientes, la reducción del coste operacional, la maximización de la cobertura de la demanda, la mejora del tiempo de respuesta, el balance de uso entre las instalaciones etc.

Estos problemas son de vital importancia en la práctica en múltiples sectores. En la logística y la gestión de la cadena de suministro, la correcta ubicación de almacenes y centros de distribución puede reducir drásticamente los costes de transporte y mejorar la eficiencia de la entrega. En el ámbito de la salud, la localización de hospitales y clínicas asegura un acceso equitativo a la atención médica y tiempos de respuesta rápidos en caso de emergencia. Asimismo, en la planificación de servicios públicos, como la ubicación de escuelas o parques de bomberos, se busca garantizar la accesibilidad cobertura del total o la mayoría de la población.

Entre los ejemplos clásicos y más estudiados de problemas de localización se encuentran:

\begin{itemize}
    \item \textbf{Problemas de Localización (Facility Location Problems)}: Se busca intentar determinar cuáles son los mejores lugares para instalar varias infraestructuras (almacenes, puntos de distribución, hospitales). El objetivo, si el problema trata únicamente de construir la infraestructura, es minimizar costes/maximizar beneficios, pero generalmente existe también un grupo de clientes o usuarios a los que hay que atender desde los puntos de distribución Con esto el objetivo puede ser reducir la distancia total para suministrar, equilibrar
el uso de las infraestructuras, y también tener restricciones de demanda, de cobertura, etc.\\
Hay ejemplos como elegir dónde ubicar almacenes, ubicar estaciones de ambulancias, colocar torres te telefonía o decidir dónde abrir nuevos comercios de una cadena de supermercados.
    \item p-mediana
    \item p-center
    \item coverage
\end{itemize}

\section{Motivación}
En un entorno cada vez más competitivo y cambiante, la localización estratégica de infraestructuras no solo debe considerar criterios tradicionales como la distancia o el coste, sino también otros factores clave como la cobertura del mercado, la accesibilidad y el equilibrio en la distribución de la demanda.

Actualmente, uno de los principales retos es maximizar el alcance de ciertos productos o servicios, garantizando que lleguen al mayor número posible de personas. Al mismo tiempo, es necesario evitar la concentración excesiva de demanda en unos pocos puntos, lo que puede provocar saturación, pérdida de calidad del servicio o ineficiencias operativas, mientras existen centros que, por tener una localización más aislada, prácticamente no reciben demanda.

Este equilibrio entre amplitud de cobertura y uso equilibrado de los recursos disponibles es especialmente importante en contextos donde hay un reducido número de emplazamientos posibles, y donde cada selección de localización afecta tanto a la eficiencia del sistema como a la experiencia del usuario o cliente final.

Al abordar el problema es importante considerar que la distancia total o el tiempo medio de viaje no es el factor más crítico. Por ejemplo, si construyes un hospital en una ciudad, el objetivo no es que la población viva lo más cerca posible, sino que se
los residentes se encuentren a una distancia razonable. 

Considera estos dos escenarios para una ciudad:
\begin{itemize}
    \item Escenario 1: El tiempo medio de viaje a un hospital es de 15 minutos, y el tiempo máximo de viaje para cualquier individuo es de 30 minutos.
    \item Escenario 2: El tiempo medio de viaje a un hospital es de 13 minutos, pero el tiempo máximo de viaje para cualquier individuo es de 1 hora
\end{itemize} 
En tiempo global, podríamos decir que el segundo sistema implementado es más eficiente, pero se dejan de lado los valores extremos extremos. Una parte significativa de la población podría tener grandes dificultades para acceder a servicios esenciales. Por el contrario, aunque el primer caso tenga un tiempo medio mayor, mejora considerablemente la accesibilidad. Esto subraya que mejorar la media no necesariamente mejora el servicio.

\section{Caso práctico}

Una red hospitalaria está planificando la ubicación de 5 centros médicos dentro de una región con una población de $400$ personas. Debido a limitaciones presupuestarias, de personal e infraestructura, se restringe su construcción a un número $20$ de posibles emplazamientos. El objetivo será encontrar qué $5$ centros, de ese total de $50$ posibles, habrá que construir,teniendo en cuénta los siguientes criterios:

\begin{itemize}
    \item Cobertura Poblacional: Los centros seleccionados deben intentar minimizar la máxima distancia o tiempo de viaje entre el conjunto de la población y los centros médicos.
    \item Capacidad: Hay que intentar que los centros médicos no queden sobresaturados. Construir un único centro médico en una zona con mucha población puede generar una buena cobertura y tiempos de viaje cortos, pero quedar saturado y generar problemas de tiempo de atención y espera.
    \item Equilibrio: No queremos tampoco que haya centros médicos con poco uso, intentando que la diferencia entre los más usados y los menos sea la menor posible, con lo que el uso quede bien repartido.
\end{itemize}
Caso de ejemplo ficticio utilizando la zona de Valencia:
\begin{figure}[H]
    \centering
    \begin{minipage}[c]{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/ejemplo_centros_medicos.png}
        \label{fig:poblacion_centros_medicos}
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\textwidth}

        Se representa con 400 puntos azules a la población de la ciudad y alrededores de Valencia. También con 20 puntos verdes las posibles localizaciones de los centros médicos.
    \end{minipage}
    \caption{Población y centros médicos}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}[c]{0.45\textwidth}
        Ejemplo de solución aleatoria, escogiendo únicamente 5 centros médicos. Podemos ver que al escogerse por el sur y oeste, queda gran parte de valencia con una importante dificultad de acceso a los mismos.
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/solucion_ejemplo_1.png}
        \label{fig:ejemplo_1}
    \end{minipage}
    \caption{Primer ejemplo de solución}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}[c]{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/solucion_ejemplo_2.png}
        \label{fig:ejemplo_2}
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\textwidth}
        Aquí ya se pueden ver mejoras, pero sigue sin ser una buena solución. Por el sur y el norte tienen aún bastante lejos los centros médicos, y hay alguno como el de la izquierda del todo, por Valencia Sud, que se utilizará relativamente poco al ir la población a los otros 2 más centricos (estos a su vez quedarán sobre saturados).
    \end{minipage}
    \caption{Segundo ejemplo de solución}
\end{figure}

\begin{figure}[H]
    \centering
    \begin{minipage}[c]{0.45\textwidth}
        Esta solución sería, de las 3, la que mejor apariencia tiene, con una dispersión de los centros médicos mejor, y solo dejando más apartada la zona sur del puerto.
    \end{minipage}
    \hfill
    \begin{minipage}[c]{0.45\textwidth}
        \includegraphics[width=\textwidth]{images/solucion_ejemplo_3.png}
        \label{fig:ejemplo_3}
    \end{minipage}
    \caption{Tercer ejemplo de solución}
\end{figure}

 Al final, con este ejemplo de juguete (su población es de casi un millón de habitantes), y una cantidad mayor de posibles emplazamientos, no sería factible buscar la mejor solución probando
 o con un algoritmo exacto. Por eso, voy a modelizar el problema matemáticamente y, con un GRASP, intentar sacar las mejores soluciones posibles, para datos generados aleatoriamente, y comprobar, 
 con resultados de un artículo previo, la viabilidad del modelo.

\section{Modelo Matemático}
3 variables a minimizar
restricciones
método exacto? (no viable)



\chapter{GRASP}
\section{Por qué el GRASP}

\section{Metaheurísticas del grasp}
monoobjetivo, multiobjetivo

\section{Implementación del grasp}
Primera versión, grasp simple con inicialización aleatoria y búsqueda local en una de las 3 variables

Segunda versión, grasp con inicialización greedy randomizada (con alpha fijo) y 2 búsquedas locales en serie

Tercera y última versión, grasp con inicialización greedy randomizada (con alpha ranodom), búsquedas locales escogidas por aprendizaje reforzado.

\chapter{Aprendizaje Reforzado}

\chapter{Experimentación y Resultados}

Instancias, comparativa, CASO DE ESTUDIO

\chapter{Conclusiones}

\chapter{Agradecimientos}
Valgrai, compañeros del máster, amigos, familia, mi tutora del TFM


\begin{thebibliography}{X}
    \bibitem{k-Balanced} \textsc{Sánchez-Oro, Jesús; López-Sánchez, Ana D.; Martínez-Gavara, Anna; Hernández-Díaz, Alfredo G.; Duarte, Abraham}. \textit{A Hybrid Strategic Oscillation with Path Relinking Algorithm for the Multiobjective k-Balanced Center Location Problem.} Mathematics, Vol. 9, No. 8, 2021, Artículo 853. \url{https://www.mdpi.com/2227-7390/9/8/853}

    \bibitem{Numerical_optimization_nocedal_wright}
    Jorge Nocedal and Stephen J. Wright.
    \newblock {\em Numerical Optimization}.
    \newblock Springer, 2nd edition, 2006.

    \bibitem{Dantzig1951} \textsc{Dantzig, George B.} \textit{Maximization of a Linear Function of Variables Subject to Linear Inequalities.} En: Koopmans, Tjalling C. (ed.). \textit{Activity Analysis of Production and Allocation}. New York: John Wiley \& Sons, Inc., 1951, pp. 339-347. \url{https://wwwf.imperial.ac.uk/~ajacquie/IC_Num_Methods/IC_Num_Methods_Docs/Literature/Dantzig2.pdf}

    \bibitem{Bre2017}
    Facundo Bre and Víctor Fachinotti.
    \newblock A computational multi-objective optimization method to improve energy efficiency and thermal comfort in dwellings.
    \newblock {\em Energy and Buildings}, 154: (missing pages, if available), August 2017.
    \newblock \href{https://doi.org/10.1016/j.enbuild.2017.08.002}{DOI: 10.1016/j.enbuild.2017.08.002}
    

\end{thebibliography}


\end{document}

